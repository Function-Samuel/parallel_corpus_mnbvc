{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168fa9b7-ce99-4517-8029-286723bae7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import re\n",
    "import hashlib\n",
    "from urllib import parse\n",
    "from urllib.request import build_opener, install_opener, urlretrieve\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5af52de0-1365-42ca-b6af-5cc0235c547e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lang_list = ['zh', 'en', 'fr', 'es', 'ru', 'ar']\n",
    "root_url = 'https://www.un.org/'\n",
    "url_seed = set()\n",
    "url_result = []\n",
    "link_pattern = r'<a href=\"((?:https?://[^/]*?\\.un\\.org)?/[^\"]*?)\"'\n",
    "media_format_list = ['avi', 'wmv', 'mpeg', 'mp4', 'mov', 'mkv', 'flv', 'f4v', 'm4v', 'rmvb', 'rm', '3gp', 'dat', 'ts',\n",
    "                     'mts', 'vob', 'bmp', 'jpg', 'png', 'tiff', 'gif', 'pcx', 'tga', 'exif', 'fpx', 'svg', 'psd', 'cdr',\n",
    "                     'pcd', 'dxf', 'ufo', 'eps', 'ai', 'raw', 'wmf', 'mp3', 'aiff', 'aac']\n",
    "base_dir = 'hayesyang/un_corpus/'\n",
    "log_dir = 'hayesyang/'\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556e2f51-19ac-4917-bbfc-f0a17d2e2cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url中含该list中的字符串则不处理\n",
    "excluded_url_pattern_list = ['search?', 'download?', 'subscribe?', 'system/403?', 'sustainabledevelopment.un.org/',\n",
    "                             'https://www.un.org/unispal/documents/?', '.pdf', '.doc', '.xls', '.ppt']\n",
    "# url符合pattern则做替换\n",
    "url_clean_pattern_list = [(r'^http://\\s*', 'https://'), (r'\\r?\\n', ''), (r'\\s*#.*', ''), (r'(?<=\\.pdf)&.*', ''),\n",
    "                          (r'(?<=asp)\\?.*', ''), (r'\\.un\\.org/../', '.un.org/'), (r'/[^./]*?/../', '/'),\n",
    "                          (r'\\s*[|/?]$', ''), (r'https://(.*?\\.un\\.org)//\\1/', r'https://\\1/'), (' ', '%20'),\n",
    "                          (r'(.*ldcportal/content/[^?\\n]*)\\?.*', r'\\1'), (r'\\t', ''), (r'\\?(?!page=).*', '')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5baffd3f-e5cb-4ee8-963e-bdc694c5f068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_url_seed():\n",
    "    global url_seed, url_result\n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    if os.path.exists(log_dir + 'url_seed.txt'):\n",
    "        with open(log_dir + 'url_seed.txt', 'r', encoding='utf8') as f:\n",
    "            lines = f.readlines()\n",
    "            url_seed = set(line.strip() for line in lines)\n",
    "    else:\n",
    "        url_seed = set(root_url + lang for lang in lang_list)\n",
    "    \n",
    "    if os.path.exists(log_dir + 'url_result.txt'):\n",
    "        with open(log_dir + 'url_result.txt', 'r', encoding='utf8') as f:\n",
    "            lines = f.readlines()\n",
    "            url_result = [{'url': line.split('\\t')[0].strip(),\n",
    "                           'status': int(line.split('\\t')[1].strip()),\n",
    "                           'path': line.split('\\t')[2].strip(),\n",
    "                           'hash': line.split('\\t')[3].strip(),\n",
    "                           'is_dup': int(line.split('\\t')[4].strip())} for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abb8fc87-05f2-4b6c-9baa-fe48090cf901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_url_result():\n",
    "    global url_seed, url_result, log_dir\n",
    "    \n",
    "    seed_content = '\\n'.join(url_seed)\n",
    "    with open(log_dir + 'url_seed.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(seed_content)\n",
    "        \n",
    "    result_content = '\\n'.join(['\\t'.join([str(item[key]) for key in item.keys()]) for item in url_result])\n",
    "    with open(log_dir + 'url_result.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(result_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1d9b2ea-2c8e-45f0-a066-5535640154c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_paths(url):\n",
    "    global base_dir\n",
    "\n",
    "    rel_name = re.sub('/$', '', re.sub(r'^https?://', '', url))\n",
    "    rel_name = parse.unquote(rel_name)\n",
    "    paths = rel_name.split('/')\n",
    "\n",
    "    if paths[0][-7:] != '.un.org':\n",
    "        return None, None\n",
    "    \n",
    "    rel_path = base_dir\n",
    "    \n",
    "    for i in range(1, len(paths) - 1):\n",
    "        if paths[i].find('?') > 0 or paths[i].find('https:') >= 0:\n",
    "            paths[i] = '/'.join(paths[i:])\n",
    "            paths = paths[:i + 1]\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        if len(paths) > 1:\n",
    "            for i in range(len(paths) - 1):\n",
    "                if not os.path.exists(rel_path + paths[i]):\n",
    "                    os.mkdir(rel_path + paths[i])\n",
    "                rel_path += paths[i] + '/'\n",
    "        else:\n",
    "            rel_path += paths[0] + '/'\n",
    "            if not os.path.exists(rel_path):\n",
    "                os.mkdir(rel_path)\n",
    "    except Exception as e:\n",
    "        print(\"%s: %s\" % (time.strftime('%Y-%m-%d %H:%M:%S'), str(e)))\n",
    "        return None, None\n",
    "\n",
    "    return rel_path, paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cb6a99b-f4eb-488d-bb12-43c04123d7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_short_name(path):\n",
    "    idx = 1\n",
    "    while os.path.exists(path + '/' + '{:0>4d}'.format(idx) + '.html'):\n",
    "        idx += 1\n",
    "    return '{:0>4d}'.format(idx) + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b2ff4ee-f2e0-43f8-bebb-034d3d0e1fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_local(url, content):\n",
    "    global base_dir\n",
    "    rel_path, paths = get_paths(url)\n",
    "    if rel_path:\n",
    "        if len(paths) == 1:\n",
    "            f_name = 'root.html'\n",
    "        else:\n",
    "            f_name = re.sub(r'\\r?\\n', '', paths[-1])\n",
    "        f_name = escape(f_name)\n",
    "        if '.' not in f_name:\n",
    "            f_name += '.html'\n",
    "        try:\n",
    "            with open(rel_path + f_name, 'w', encoding='utf8') as f:\n",
    "                f.write(content)\n",
    "            return 1, rel_path.replace(base_dir, '')\n",
    "        except Exception as e:\n",
    "            if 'name too long' in str(e):\n",
    "                f_name = get_short_name(rel_path)\n",
    "                try:\n",
    "                    with open(rel_path + f_name, 'w', encoding='utf8') as f:\n",
    "                        f.write(content)\n",
    "                    return 1, rel_path.replace(base_dir, '')\n",
    "                except Exception as e2:\n",
    "                    print(\"%s: %s\" % (time.strftime('%Y-%m-%d %H:%M:%S'), str(e2)))\n",
    "            else:\n",
    "                print(\"%s: %s\" % (time.strftime('%Y-%m-%d %H:%M:%S'), str(e)))\n",
    "            return -1, None\n",
    "    else:\n",
    "        return -1, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3873c42-044c-48d4-b30c-8eaaec74df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def escape(c):\n",
    "    # Windows下文件名无法包含以下几个字符，需要转义\n",
    "    return c.replace('?', '_QMARK_').replace(':', '_COLON_').replace('|', '_PIPE_').replace('/', '_SLASH_')\\\n",
    "        .replace('*', '_STAR_').replace('\"', '_QT_').replace('\\\\', '_BS_').replace('<', '_LT_').replace('>', '_GT_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f35b1687-3e65-4f12-a37c-1b38221b2edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    global url_status\n",
    "    \n",
    "    header = {\n",
    "        'user-agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/96.0.4664.110 Safari/537.36 \"\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, headers=header, timeout=10)\n",
    "        html = resp.content.decode('utf8')\n",
    "        return html\n",
    "    except Exception as e:\n",
    "        print(\"%s: %s got exception - %s\" % (time.strftime('%Y-%m-%d %H:%M:%S'), url, str(e)))\n",
    "        if 'codec can\\'t decode' in str(e):\n",
    "            return 'ERR_STATUS -2'\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31900eca-1333-4cfe-9891-b9c30c50149d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_media(url):\n",
    "    if url.find('.') > 0:\n",
    "        tmp = re.sub(r'^.*\\.', '', url).lower()\n",
    "        if tmp in media_format_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_excluded_url_pattern(url):\n",
    "    if any(excluded_pattern in url for excluded_pattern in excluded_url_pattern_list):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def clean_url(url):\n",
    "    for pattern, repl in url_clean_pattern_list:\n",
    "        url = re.sub(pattern, repl, url)\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94e6e85-656e-4dce-aa7f-d19c98c7b9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_urls(curr_url, html):\n",
    "    urls = []\n",
    "    base_url = re.sub(r'(?<=\\.un\\.org)/.*', '', curr_url)\n",
    "    matched_urls = re.findall(link_pattern, html)\n",
    "    for url in matched_urls:\n",
    "        url = url.strip()\n",
    "        if url[0] == '/':\n",
    "            # 把相对路径改为绝对路径\n",
    "            url = base_url + url\n",
    "        if has_excluded_url_pattern(url):\n",
    "            # 如果url中包含某些字符串则不处理\n",
    "            continue\n",
    "        elif is_media(url):\n",
    "            # 如果是媒体格式的文件则不处理\n",
    "            continue\n",
    "        # 清洗url\n",
    "        url = clean_url(url)\n",
    "        if url not in urls:\n",
    "            urls.append(url)\n",
    "    \n",
    "    return urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a7699d-17f3-4d35-bbd8-29bc53694279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_md5(content):\n",
    "    md5 = hashlib.md5()\n",
    "    md5.update(content.encode('utf8'))\n",
    "    return md5.hexdigest()\n",
    "\n",
    "def make_content_item(url, status, path, content):\n",
    "    global base_dir\n",
    "    if content:\n",
    "        md5 = get_md5(content)\n",
    "    else:\n",
    "        md5 = None\n",
    "    item = {'url': url, 'status': status, 'path': path, 'hash': md5, 'is_duplicate': 0}\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe65a01-d87b-4dda-88fa-4d7389616957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_url(url, hash_set):\n",
    "    global counter, url_seed, url_result\n",
    "    has_new = False\n",
    "    \n",
    "    if re.search(r'\\.(?:pdf|docx?|pptx?|xlsx?)(?:[^A-Za-z]|$)', url):\n",
    "        new_result = make_content_item(url, -1, None, None)\n",
    "    else:\n",
    "        html = get_html(url)\n",
    "        if html:\n",
    "            if html.startswith('ERR_STATUS'):\n",
    "                status = int(html.replace('ERR_STATUS '))\n",
    "                new_result = make_content_item(url, status, None, None)\n",
    "            else:\n",
    "                status, rel_path = save_local(url, html)\n",
    "                new_result = make_content_item(url, status, rel_path, html)\n",
    "                if new_result['hash'] in hash_set:\n",
    "                    new_result['is_duplicate'] = 1\n",
    "                else:\n",
    "                    hash_set.add(new_result['hash'])\n",
    "\n",
    "                urls = parse_urls(url, html)\n",
    "                if len(urls) > 0:\n",
    "                    for new_url in urls:\n",
    "                        if re.sub('/$', '', new_url) in url_seed:\n",
    "                            continue\n",
    "                        url_seed.add(new_url)\n",
    "                        has_new = True\n",
    "        else:\n",
    "            new_result = make_content_item(url, -1, None, None)\n",
    "    \n",
    "    url_result.append(new_result)\n",
    "    counter += 1\n",
    "    if counter % 500 == 0:\n",
    "        print(\"%s: seed %i, content %i\" % (time.strftime('%Y-%m-%d %H:%M:%S'), len(url_seed), len(url_result)))\n",
    "        save_url_result()\n",
    "        \n",
    "    return has_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1627cd25-a5a2-4ea5-84c4-c7590e8eabdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def run_threads(num_threads):\n",
    "    global url_seed, url_result\n",
    "    \n",
    "    hash_set = set([item['hash'] for item in url_result])\n",
    "    processed_url_list = [item['url'] for item in url_result]\n",
    "    to_process_url = [url for url in url_seed if url not in processed_url_list]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(process_url, url, hash_set) for url in to_process_url]\n",
    "        \n",
    "    results = [future.result() for future in futures]\n",
    "    \n",
    "    save_url_result()\n",
    "\n",
    "    has_new = any(result for result in results)\n",
    "    return has_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d67976b-e01d-402f-98a0-7e2be38b1900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initialize_url_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c767ad8d-bf49-475e-b631-e0e64d11dab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "has_new_url = run_threads(num_threads=6)\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c02e9-5bc5-4b98-854e-c40572e48a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_iter = 1\n",
    "while has_new_url and num_iter < 5:\n",
    "    start = time.perf_counter()\n",
    "    has_new_url = run_threads(num_threads=6)\n",
    "    print('iter %d costs %f' % (num_iter, time.perf_counter() - start))\n",
    "    num_iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
